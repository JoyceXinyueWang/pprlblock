import os
import bisect
from memory_profiler import profile

from pprlindex import PPRLIndex
from config import SORTED_FIRST_VAL


class PPRLIndexKAnonymousSortedNeighbour(PPRLIndex):
  """Class that implements a sorted neighbourhood based PPRL indexing
     technique.

     Blocks are generated by sorting reference values, and inserting the
     values from the databases into an inverted index where reference values
     are the keys. Blocks are then formed that each contain at least k
     records.
  """

  # --------------------------------------------------------------------------

  def __init__(self, k, sim_measure, min_sim_threshold, overlap, sim_or_size):
    """Initialise the class and set the required parameters.

       Arguments:
       - k                  The minimum block size (in number of records that
                            need to be in a block).
       - sim_measure        A function which takes two strings as input and
                            returns a similarity value between 0 and 1.
       - min_sim_threshold  A similarity threshold between 0 and 1 which is
                            used to decide if a value is to be added to an
                            existing cluster (if a similarity value is equal
                            to or larger than this minimum threshold, or if a
                            new cluster is to be generated (if the similarity
                            is below this threshold).
       - overlap            An integer value that is used to generate
                            overlapping blocks when generating candidate
                            record pairs.
       - sim_or_size        The merging of blocks is either determined by the
                            minimum similarity between adjacent reference
                            values, or by merging blocks until they each
                            contain k record identifiers.
    """

    self.k =                 k
    self.sim_measure =       sim_measure
    self.min_sim_threshold = min_sim_threshold
    self.overlap =           overlap

    assert sim_or_size in ['SIM','SIZE']
    self.sim_or_size =       sim_or_size

    self.ref_val_list = None  # List of selected reference values

    self.ref_ind_dict = None  # Reference values with integer values as keys
                              # (with reference values sorted)

  # --------------------------------------------------------------------------
  def __sort_ref_values__(self):
    """Sort the reference values and assign an integer value (starting from 0)
       to each according to this sorting.
    """

    assert self.ref_val_list != None

    sort_ref_val_list = sorted(self.ref_val_list)

    ref_ind_dict = {}

    ref_ind_dict[0] = SORTED_FIRST_VAL  # Smallest possible value

    ind = 1
    for ref_val in sort_ref_val_list:
      ref_ind_dict[ind] = ref_val
      ind += 1

    self.ref_ind_dict =      ref_ind_dict
    self.sort_ref_val_list = sort_ref_val_list

  # --------------------------------------------------------------------------
  def __generate_sorted_index__(self, rec_dict, attr_select_list):
    """Generate the blocks for the given record dictionary. Each record (its
       record identifier) is inserted into one block according to the sorting
       key values.
    """

    ## Two different max block size criteria:
    # a) min similarity between reference values
    # b) max number of records in a block to be merged

    assert rec_dict !=          None
    assert self.ref_ind_dict != None

    k =                 self.k
    m =                 5
    sort_ref_val_list = self.sort_ref_val_list
    ref_ind_dict =      self.ref_ind_dict

    val_list =          self.ref_val_list
    sim_measure =       self.sim_measure
    min_sim_threshold = self.min_sim_threshold

    ref_val_dict = {}  # Reference values and corresponding attribute values
    ref_val_dict[SORTED_FIRST_VAL] = [] # Empty list of attribute for this block

    for ref_val in sort_ref_val_list:
      ref_val_dict[ref_val] = []        # Initialize each block with empty list

    block_dict = {}  # Resulting blocks generated
    blk_keys = []    # Resulting block keys

    num_rec_done = 0

    # Insert the records into the sorted reference dictionary
    #
    for (rec_id, rec_list) in rec_dict.items():
      num_rec_done += 1
      if (num_rec_done % 10000 == 0):
        print(num_rec_done, len(rec_dict))

      # Generate the SKV for this record
      #
      sk_val = ''
      for col_num in attr_select_list:
        sk_val += rec_list[col_num]

      # Find the position of this SKV in the sorted list of ref vals and
      # insert it into the corresponding list of record identifiers in the
      # reference dictionary
      #
      pos = bisect.bisect(sort_ref_val_list, sk_val)
      ref_val =   ref_ind_dict[pos]
      skvs_list = ref_val_dict[ref_val]
      #skvs_list.append((sk_val,rec_id))  # Store value and record identifier
      skvs_list.append(rec_id)
      ref_val_dict[ref_val] = skvs_list

    len_sort_ref_list = len(sort_ref_val_list)

    # a) max block criteria - min similarity between ref values
    if self.sim_or_size == 'SIM':
      # Merge blocks if they contain less than k elements
      #
      i = 0
      while i < len_sort_ref_list:
        num_elements = 0
        j = 0
        this_blk_elements_list = []

        sim_val = 0.0
        # The minimum number of elements in a block must be k, while the maximum
        # num of elements depends on the similarity between the ref values
        #
        while (((num_elements <= k) and (i+j < len_sort_ref_list)) or \
              ((sim_val >= min_sim_threshold) and (i+j < len_sort_ref_list))):
          this_ref_val =            ref_ind_dict[i+j]
          this_element_list =       ref_val_dict[this_ref_val]
          num_elements +=           len(this_element_list)
          this_blk_elements_list += this_element_list

          # Similarity of the next (if not the last) ref value with this ref value
          #
          if ((i+j+1) != len_sort_ref_list):
            next_ref_val = ref_ind_dict[i+j+1]
            min_len = int(3*min(len(this_ref_val),len(next_ref_val))/4)
            sim_val = sim_measure(this_ref_val[:min_len], next_ref_val[:min_len])
            if sim_val >= 0.95:
              print(this_ref_val, next_ref_val)

          j += 1

        # If a block contains less than k elements (probably the last block)
        # merge it with the previous block
        #
        if (len(this_blk_elements_list) < k):
          prev_blk_str = '_'+str(i-1)+'_'
          prev_blk_id = next(k for (k,v) in block_dict.items() if \
                      prev_blk_str in k)
          prev_blk_elements_list =  block_dict[prev_blk_id]
          this_blk_elements_list += prev_blk_elements_list
          block_id = prev_blk_id
          del block_dict[prev_blk_id]  # Delete this block and add a new
                                     # merged block
          blk_keys.remove(prev_blk_id)
        else:
          block_id = 'b_'

        # Generate the block identifier of this block consisting of the indices
        # of all the reference values in the block
        #
        for b in range(j):
          block_id += str(i+b)+'_'

        # Insert the list of record identifiers for this block into final dict
        #
        block_dict[block_id] = this_blk_elements_list
        blk_keys.append(block_id)
        i += j

    # b) max block criteria - max number of records in a block to be merged
    # If the maximum block size is used to determine the merging of blocks
    # instead of similarity between reference values.
    # 2) find the smallest blocks each time with less than k records and
    # merge with the smallest nearest blocks.
    #
    elif (self.sim_or_size == 'SIZE'):
      blk_keys = []
      blk_size = {}
      for ref_ind in ref_ind_dict:
        ref_val = ref_ind_dict[ref_ind]
        attr_vals = ref_val_dict[ref_val]
        blk_id = 'b_'+str(ref_ind)+'_'
        block_dict[blk_id]=attr_vals
        blk_keys.append(blk_id)
        blk_size[blk_id] = len(attr_vals)

      merge_block = ''
      min_size_blk = min(blk_size, key=blk_size.get)
      min_size = blk_size[min_size_blk]
      while (min_size < k and len(blk_keys)>1):
        bid = min_size_blk
        s = blk_keys.index(bid)
        blk_vals = block_dict[min_size_blk]
        if s!=0 and s!= len(blk_keys)-1:     ## middle blocks
          prev_blk_id = blk_keys[s-1]
          prev_blk_vals = block_dict[prev_blk_id]
          num_prev_blk_vals = len(prev_blk_vals)
          next_blk_id = blk_keys[s+1]
          next_blk_vals = block_dict[next_blk_id]
          num_next_blk_vals = len(next_blk_vals)
          if num_prev_blk_vals < num_next_blk_vals:
            merge_block = 'prev'
          else:
            merge_block = 'next'
        elif s == 0:                         ## first block
          next_blk_id = blk_keys[s+1]
          next_blk_vals = block_dict[next_blk_id]
          merge_block = 'next'
        elif s == len(blk_keys)-1:           ## last block
          prev_blk_id = blk_keys[s-1]
          prev_blk_vals = block_dict[prev_blk_id]
          merge_block = 'prev'

        if merge_block == 'prev':     #merge with next block
          prev_blk_vals += blk_vals
          new_blk_id = prev_blk_id + bid[2:]
          block_dict[new_blk_id] = prev_blk_vals #new block
          del block_dict[prev_blk_id] #del prev block
          blk_keys[s-1] = new_blk_id
          del blk_keys[s]
          blk_size[new_blk_id] = len(prev_blk_vals)
          del blk_size[prev_blk_id]
          del block_dict[bid] #del this block
          del blk_size[bid]
        elif merge_block == 'next':    #merge with previous block
          next_blk_vals += blk_vals
          new_blk_id = bid + next_blk_id[2:]
          block_dict[new_blk_id] = next_blk_vals #new block
          del block_dict[next_blk_id] #del next block
          blk_keys[s+1] = new_blk_id
          del blk_keys[s]
          blk_size[new_blk_id] = len(next_blk_vals)
          del blk_size[next_blk_id]
          del block_dict[bid]  #del this block
          del blk_size[bid]

        min_size_blk = min(blk_size, key=blk_size.get)
        min_size = blk_size[min_size_blk]

    #print block_dict.keys()
    return block_dict

  # --------------------------------------------------------------------------
  
  def build_index_alice(self, attr_select_list):
    """Build the index for Alice assuming the sorted reference values have
       been generated.

       Argument:
       - attr_select_list  A list of column numbers that will be used to
                           extract attribute values from the given records,
                           and concatenate them into one string value which is
                           then used as reference value (and added to the
                           result list if it differs from all other reference
                           values).
    """

    self.attr_select_list_alice = attr_select_list

    if (self.ref_ind_dict == None):  # Only needs to be done once (same
      self.__sort_ref_values__()     # reference values for both database
                                     # owners)

    assert self.rec_dict_alice != None

    self.index_alice = self.__generate_sorted_index__(self.rec_dict_alice,
                                                      attr_select_list)
    print('Index for Alice contains %d blocks' % (len(self.index_alice)))

    stat = self.block_stats(self.index_alice)
    min_block_size,med_blk_size,max_block_size,avr_block_size,std_dev,blk_len_list = stat

    wr_file_name = './logs/SNC_3PSim_alice.csv'
    wr_file = open(wr_file_name, 'a')

    sum = 0.0
    for i in blk_len_list:
      sum = sum + (i - avr_block_size)*(i - avr_block_size)
      wr_file.write(str(i)+',')
    wr_file.write(os.linesep)
    wr_file.close()

    return min_block_size,med_blk_size,max_block_size,avr_block_size,std_dev

  # --------------------------------------------------------------------------
  def build_index_bob(self, attr_select_list):
    """Build the index for Bob assuming the sorted reference values have
       been generated.

       Argument:
       - attr_select_list  A list of column numbers that will be used to
                           extract attribute values from the given records,
                           and concatenate them into one string value which is
                           then used as reference value (and added to the
                           result list if it differs from all other reference
                           values).
    """

    self.attr_select_list_bob = attr_select_list

    if (self.ref_ind_dict == None):  # Only needs to be done once (same
      self.__sort_ref_values__()     # reference values for both database
                                     # owners)

    assert self.rec_dict_bob != None

    self.index_bob = self.__generate_sorted_index__(self.rec_dict_bob,
                                                    attr_select_list)
    print('Index for Bob contains %d blocks' % (len(self.index_bob)))

    stat = self.block_stats(self.index_bob)
    min_block_size,med_blk_size,max_block_size,avr_block_size,std_dev,blk_len_list = stat

    wr_file_name = './logs/SNC_3PSim_bob.csv'
    wr_file = open(wr_file_name, 'a')

    sum = 0.0
    for i in blk_len_list:
      sum = sum + (i - avr_block_size)*(i - avr_block_size)
      wr_file.write(str(i)+',')
    wr_file.write(os.linesep)
    wr_file.close()

    return min_block_size,med_blk_size,max_block_size,avr_block_size,std_dev

  # --------------------------------------------------------------------------

  def generate_blocks(self):
    """Method which generates the blocks based on the built two index data
       structures.
    """

    block_dict = {}  # contains final candidate record pairs

    # How many blocks to overlap in record pair generation
    #
    index_alice = self.index_alice
    index_bob =   self.index_bob
    overlap =     self.overlap
    k =           self.k

    bob_block_lookup = {} # Lookup dictionary that contains the block ids for
                          # each reference id in Bob's index

    # Build Lookup dictionary for Bob's blocks
    #
    for block_id in self.index_bob.keys():
      bob_block_nums = block_id.split('_')
      bob_blocks =     bob_block_nums[1:-1]
      for blk in bob_blocks:
        bob_block_lookup[blk] = block_id

    #print 'bob_block_lookup', bob_block_lookup
    cand_pairs_list = []  # contains unique candidate pairs
    cand_blk_key = 0

    # Iterate through Alice's blocks
    #
    for (block_id, block_vals) in self.index_alice.items():
      assert len(block_vals) >= k, (block_id, len(block_vals))

      # Get the ids of reference values in each block
      #
      block_nums_list = block_id.split('_')

      # First element will be 'b', and last will be empty, so not used
      #
      block_nums = block_nums_list[1:-1]

      # Calculate overlap blocks
      #
      lower_overlap_bound = int(min(block_nums))-overlap
      upper_overlap_bound = int(max(block_nums))+overlap
      if lower_overlap_bound > 0:
        block_nums.insert(0,str(lower_overlap_bound))  # Append at front
      if upper_overlap_bound < len(self.sort_ref_val_list):
        block_nums.append(str(upper_overlap_bound))  # Append at end

      alice_blk_list = block_vals
      bob_blks =       set([]) # Bob's blocks that have this ref value
      bob_blk_list =   []      # Bob's rec ids in these blocks

      # Find Bob's blocks that have this reference value
      #
      for block_num in block_nums:
        bob_block = bob_block_lookup[block_num]
        bob_blks.add(bob_block) # Only keep unique values

      list(bob_blks)

      # Get all Bob's record ids that are in these blocks
      #
      for bob_blk in bob_blks:
        assert len(index_bob[bob_blk]) >= k, (bob_blk,len(index_bob[bob_blk]))

        bob_blk_list += index_bob[bob_blk]

      block_dict[cand_blk_key] = (alice_blk_list, bob_blk_list)

      cand_blk_key += 1

    self.block_dict = block_dict
    #print block_dict
    print('Final indexing contains %d blocks' % (len(block_dict)))

    return len(block_dict)
